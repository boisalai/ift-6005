{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de l'agent principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "DB_PATH = DATA_DIR / \"food.duckdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3601655 produits dans la base de données.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    \"\"\"État de l'agent pour suivre le contexte de la conversation\"\"\"\n",
    "    conversation_history: List[Dict[str, Any]]\n",
    "    current_context: Dict[str, Any]\n",
    "    \n",
    "class MainAgent:\n",
    "    def __init__(self, db_path: str):\n",
    "        \"\"\"Initialise l'agent avec la base de données DuckDB\"\"\"\n",
    "        self.conn = duckdb.connect(db_path)\n",
    "        self.state = AgentState(\n",
    "            conversation_history=[],\n",
    "            current_context={}\n",
    "        )\n",
    "    \n",
    "    def analyze_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyse la requête pour déterminer l'intention et les paramètres\"\"\"\n",
    "        # Version simple - à améliorer avec LLM\n",
    "        analysis = {\n",
    "            \"intent\": \"general_query\",\n",
    "            \"parameters\": {},\n",
    "            \"requires_sql\": False\n",
    "        }\n",
    "        \n",
    "        # Mots clés basiques pour détecter l'intention\n",
    "        if any(word in query.lower() for word in [\"combien\", \"nombre\", \"total\"]):\n",
    "            analysis[\"intent\"] = \"count_query\"\n",
    "            analysis[\"requires_sql\"] = True\n",
    "            \n",
    "        return analysis\n",
    "    \n",
    "    def execute_query(self, analysis: Dict[str, Any]) -> str:\n",
    "        \"\"\"Exécute la requête en fonction de l'analyse\"\"\"\n",
    "        if analysis[\"requires_sql\"]:\n",
    "            # Example simple de requête SQL\n",
    "            result = self.conn.execute(\"SELECT COUNT(*) FROM products\").fetchone()\n",
    "            return f\"Il y a {result[0]} produits dans la base de données.\"\n",
    "            \n",
    "        return \"Je ne sais pas encore comment répondre à cette question.\"\n",
    "    \n",
    "    def process_query(self, query: str) -> str:\n",
    "        \"\"\"Point d'entrée principal pour traiter une requête\"\"\"\n",
    "        # Analyse la requête\n",
    "        analysis = self.analyze_query(query)\n",
    "        \n",
    "        # Mise à jour du contexte\n",
    "        self.state.current_context = {\n",
    "            \"last_query\": query,\n",
    "            \"analysis\": analysis\n",
    "        }\n",
    "        \n",
    "        # Exécute la requête\n",
    "        response = self.execute_query(analysis)\n",
    "        \n",
    "        # Met à jour l'historique\n",
    "        self.state.conversation_history.append({\n",
    "            \"query\": query,\n",
    "            \"analysis\": analysis,\n",
    "            \"response\": response\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Ferme la connexion à la base de données\"\"\"\n",
    "        self.conn.close()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "agent = MainAgent(DB_PATH)\n",
    "response = agent.process_query(\"Combien y a-t-il de produits dans la base de données ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajoutons la capacité de générer des requêtes SQL basées sur l'intention détectée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3601655 produits dans la base de données.\n",
      "Il y a 3601655 produits dans la base de données.\n",
      "Distribution des Nutriscores:\n",
      "- Nutriscore a: 161848 produits\n",
      "- Nutriscore b: 133265 produits\n",
      "- Nutriscore c: 245111 produits\n",
      "- Nutriscore d: 305603 produits\n",
      "- Nutriscore e: 326479 produits\n",
      "- Nutriscore not-applicable: 73417 produits\n",
      "- Nutriscore unknown: 2334933 produits\n",
      "- Nutriscore None: 20999 produits\n",
      "\n",
      "Top 10 des catégories:\n",
      "- None: 1925020 produits\n",
      "- : 139033 produits\n",
      "- Snacks: 33766 produits\n",
      "- Snacks, Sweet snacks, Confectioneries: 14597 produits\n",
      "- Condiments, Sauces, Groceries: 13532 produits\n",
      "- Dairies, Fermented foods, Fermented milk products, Cheeses: 12018 produits\n",
      "- Snacks, Sweet snacks, Biscuits and cakes, Biscuits: 11143 produits\n",
      "- Beverages: 9528 produits\n",
      "- Desserts, Frozen foods, Frozen desserts: 9520 produits\n",
      "- Plant-based foods and beverages, Plant-based foods, Cereals and potatoes, Breads: 7888 produits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from typing import Dict, List, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    \"\"\"État de l'agent pour suivre le contexte de la conversation\"\"\"\n",
    "    conversation_history: List[Dict[str, Any]]\n",
    "    current_context: Dict[str, Any]\n",
    "    \n",
    "class MainAgent:\n",
    "    def __init__(self, db_path: str):\n",
    "        \"\"\"Initialise l'agent avec la base de données DuckDB\"\"\"\n",
    "        self.conn = duckdb.connect(db_path)\n",
    "        self.state = AgentState(\n",
    "            conversation_history=[],\n",
    "            current_context={}\n",
    "        )\n",
    "    \n",
    "    def analyze_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyse la requête pour déterminer l'intention et les paramètres\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        analysis = {\n",
    "            \"intent\": \"general_query\",\n",
    "            \"parameters\": {},\n",
    "            \"requires_sql\": False,\n",
    "            \"sql_query\": None\n",
    "        }\n",
    "        \n",
    "        if any(word in query_lower for word in [\"combien\", \"nombre\", \"total\"]):\n",
    "            analysis[\"intent\"] = \"count_query\"\n",
    "            analysis[\"requires_sql\"] = True\n",
    "            analysis[\"sql_query\"] = \"SELECT COUNT(*) FROM products\"\n",
    "            \n",
    "        elif \"nutriscore\" in query_lower:\n",
    "            analysis[\"intent\"] = \"nutriscore_query\"\n",
    "            analysis[\"requires_sql\"] = True\n",
    "            analysis[\"sql_query\"] = \"\"\"\n",
    "                SELECT nutriscore_grade, COUNT(*) as count \n",
    "                FROM products \n",
    "                GROUP BY nutriscore_grade \n",
    "                ORDER BY nutriscore_grade\"\"\"\n",
    "                \n",
    "        elif \"catégories\" in query_lower or \"categories\" in query_lower:\n",
    "            analysis[\"intent\"] = \"category_query\"\n",
    "            analysis[\"requires_sql\"] = True\n",
    "            analysis[\"sql_query\"] = \"\"\"\n",
    "                SELECT categories, COUNT(*) as count \n",
    "                FROM products \n",
    "                GROUP BY categories \n",
    "                ORDER BY count DESC \n",
    "                LIMIT 10\"\"\"\n",
    "            \n",
    "        return analysis\n",
    "    \n",
    "    def execute_query(self, analysis: Dict[str, Any]) -> str:\n",
    "        \"\"\"Exécute la requête en fonction de l'analyse\"\"\"\n",
    "        if not analysis[\"requires_sql\"]:\n",
    "            return \"Je ne sais pas encore comment répondre à cette question.\"\n",
    "            \n",
    "        result = self.conn.execute(analysis[\"sql_query\"]).fetchall()\n",
    "        \n",
    "        if analysis[\"intent\"] == \"count_query\":\n",
    "            return f\"Il y a {result[0][0]} produits dans la base de données.\"\n",
    "            \n",
    "        elif analysis[\"intent\"] == \"nutriscore_query\":\n",
    "            response = \"Distribution des Nutriscores:\\n\"\n",
    "            for grade, count in result:\n",
    "                response += f\"- Nutriscore {grade}: {count} produits\\n\"\n",
    "            return response\n",
    "            \n",
    "        elif analysis[\"intent\"] == \"category_query\":\n",
    "            response = \"Top 10 des catégories:\\n\"\n",
    "            for category, count in result:\n",
    "                response += f\"- {category}: {count} produits\\n\"\n",
    "            return response\n",
    "            \n",
    "        return \"Je ne sais pas comment formater cette réponse.\"\n",
    "    \n",
    "    def process_query(self, query: str) -> str:\n",
    "        \"\"\"Point d'entrée principal pour traiter une requête\"\"\"\n",
    "        # Analyse la requête\n",
    "        analysis = self.analyze_query(query)\n",
    "        \n",
    "        # Mise à jour du contexte\n",
    "        self.state.current_context = {\n",
    "            \"last_query\": query,\n",
    "            \"analysis\": analysis\n",
    "        }\n",
    "        \n",
    "        # Exécute la requête\n",
    "        response = self.execute_query(analysis)\n",
    "        \n",
    "        # Met à jour l'historique\n",
    "        self.state.conversation_history.append({\n",
    "            \"query\": query,\n",
    "            \"analysis\": analysis,\n",
    "            \"response\": response\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Ferme la connexion à la base de données\"\"\"\n",
    "        self.conn.close()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "agent = MainAgent(DB_PATH)\n",
    "print(agent.process_query(\"Combien y a-t-il de produits dans la base de données ?\"))\n",
    "print(agent.process_query(\"Combien y a-t-il de produits ?\"))\n",
    "print(agent.process_query(\"Montre-moi la distribution des nutriscores\"))\n",
    "print(agent.process_query(\"Quelles sont les principales catégories ?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examiner la structure de la base DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schéma de la table ===\n",
      "                       column_name  data_type is_nullable\n",
      "0                      additives_n    INTEGER         YES\n",
      "1                   additives_tags  VARCHAR[]         YES\n",
      "2                   allergens_tags  VARCHAR[]         YES\n",
      "3                           brands    VARCHAR         YES\n",
      "4                      brands_tags  VARCHAR[]         YES\n",
      "..                             ...        ...         ...\n",
      "104          unknown_ingredients_n    INTEGER         YES\n",
      "105         unknown_nutrients_tags  VARCHAR[]         YES\n",
      "106                  vitamins_tags  VARCHAR[]         YES\n",
      "107  with_non_nutritive_sweeteners    INTEGER         YES\n",
      "108                with_sweeteners    INTEGER         YES\n",
      "\n",
      "[109 rows x 3 columns]\n",
      "\n",
      "=== Statistiques de base ===\n",
      "   total_rows  unique_nutriscores  unique_categories\n",
      "0     3601655                   7             245672\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "DB_PATH = Path(\"../data\") / \"food.duckdb\"\n",
    "con = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "# Afficher le schéma\n",
    "schema_query = \"\"\"\n",
    "SELECT \n",
    "    column_name,\n",
    "    data_type,\n",
    "    is_nullable\n",
    "FROM information_schema.columns \n",
    "WHERE table_name = 'products'\n",
    "ORDER BY column_name;\n",
    "\"\"\"\n",
    "\n",
    "# Afficher quelques statistiques de base\n",
    "stats_query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(*) as total_rows,\n",
    "    COUNT(DISTINCT nutriscore_grade) as unique_nutriscores,\n",
    "    COUNT(DISTINCT categories) as unique_categories\n",
    "FROM products;\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Schéma de la table ===\")\n",
    "print(con.execute(schema_query).df())\n",
    "\n",
    "print(\"\\n=== Statistiques de base ===\")\n",
    "print(con.execute(stats_query).df())\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama avec Mistral-7B\n",
    "\n",
    "Le code ci-dessous montre comment poser une question simple à Mistral-7B et obtenir une réponse.\n",
    "\n",
    "Les choix de paramètres de génération sont décrits [ici](https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Bonjour! Oui, je suis familière avec DuckDB. C'est un système de gestion de bases de données en temps réel et open source écrit en Rust. Il est optimisé pour le traitement de petites à moyennes quantités de données et offre une performance comparable à celle de SQLite, mais avec des fonctionnalités supplémentaires telles que l'intégration de moteurs de machine learning et la possibilité d'exécuter du code Rust natif."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ollama import Client\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Initialiser Ollama\n",
    "ollama = Client(host='http://localhost:11434')\n",
    "\n",
    "def simple_question(question: str) -> str:\n",
    "    \"\"\"Fonction pour poser une question simple à Ollama\"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='mistral:7b',\n",
    "            messages=[{'role': 'user', 'content': question}],\n",
    "            options={\n",
    "                'temperature': 0.4  # Contrôle la créativité (0-1)\n",
    "            }\n",
    "        )\n",
    "        return response['message']['content'].strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying question: {e}\")\n",
    "\n",
    "prompt = \"Bonjour Ollama, connais-tu DuckDB?\"\n",
    "response = simple_question(prompt)\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "from typing import Dict\n",
    "\n",
    "class LLMAgent:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise la connexion à Ollama\"\"\"\n",
    "        self.client = Client(host='http://localhost:11434')\n",
    "        self.model = 'mistral:7b'\n",
    "        \n",
    "    def generate_sql(self, query: str, schema: Dict) -> str:\n",
    "        \"\"\"Génère une requête SQL à partir d'une question en langage naturel\"\"\"\n",
    "        prompt = f\"\"\"En tant qu'expert SQL, génère une requête SQL sur une base DuckDB pour répondre à cette question: \"{query}\"\n",
    "\n",
    "Schéma de la table products:\n",
    "{schema}\n",
    "\n",
    "Retourne uniquement la requête SQL, sans explications.\"\"\"\n",
    "        \n",
    "        response = self.client.chat(model=self.model, messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt\n",
    "        }])\n",
    "        \n",
    "        return response['message']['content'].strip()\n",
    "\n",
    "    def classify_query(self, query: str) -> Dict:\n",
    "        \"\"\"Classifie le type de requête\"\"\"\n",
    "        prompt = f\"\"\"Classifie cette question: \"{query}\"\n",
    "        \n",
    "Retourne uniquement un objet JSON avec:\n",
    "- intent: le type de requête (count, category, nutriscore, etc.)\n",
    "- requires_sql: true/false si une requête SQL est nécessaire\n",
    "\n",
    "Example: {{\"intent\": \"count_query\", \"requires_sql\": true}}\"\"\"\n",
    "        \n",
    "        response = self.client.chat(model=self.model, messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt\n",
    "        }])\n",
    "        \n",
    "        # Note: Il faudrait ajouter la validation du JSON retourné\n",
    "        return response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je comprends que le modèle LLM doit connaître et comprendre le schéma de la base DuckDB pour généer la requête SQL à partir d'une question en langage naturel.\n",
    "\n",
    "Mais, je ne la comprend pas moi-même. Il faudrait peut-être que j'examine la base DuckDB afin d'éliminer les colonnes inutiles et documenter les colonnes restantes. Comment faire cela?\n",
    "\n",
    "Voici une requête pour analyser le schéma et obtenir des statistiques basiques sur chaque colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schéma ===\n",
      "                       column_name  data_type is_nullable\n",
      "0                      additives_n    INTEGER         YES\n",
      "1                   additives_tags  VARCHAR[]         YES\n",
      "2                   allergens_tags  VARCHAR[]         YES\n",
      "3                           brands    VARCHAR         YES\n",
      "4                      brands_tags  VARCHAR[]         YES\n",
      "..                             ...        ...         ...\n",
      "104          unknown_ingredients_n    INTEGER         YES\n",
      "105         unknown_nutrients_tags  VARCHAR[]         YES\n",
      "106                  vitamins_tags  VARCHAR[]         YES\n",
      "107  with_non_nutritive_sweeteners    INTEGER         YES\n",
      "108                with_sweeteners    INTEGER         YES\n",
      "\n",
      "[109 rows x 3 columns]\n",
      "\n",
      "=== Stats de base ===\n",
      "   total_rows  unique_products  unique_nutriscores\n",
      "0     3601655          2305601                   7\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "DB_PATH = Path(\"../data/food.duckdb\")\n",
    "con = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "# Obtenir le schéma\n",
    "schema_query = \"\"\"\n",
    "SELECT column_name, data_type, is_nullable\n",
    "FROM information_schema.columns \n",
    "WHERE table_name = 'products'\n",
    "ORDER BY column_name;\n",
    "\"\"\"\n",
    "\n",
    "# Statistiques de base\n",
    "stats_query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(*) as total_rows,\n",
    "    COUNT(DISTINCT product_name) as unique_products,\n",
    "    COUNT(DISTINCT nutriscore_grade) as unique_nutriscores\n",
    "FROM products;\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Schéma ===\")\n",
    "print(con.execute(schema_query).df())\n",
    "print(\"\\n=== Stats de base ===\")\n",
    "print(con.execute(stats_query).df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_schema():\n",
    "    DB_PATH = Path(\"../data/food.duckdb\")\n",
    "    con = duckdb.connect(str(DB_PATH))\n",
    "   \n",
    "    # 1. Obtenir le schéma\n",
    "    schema_query = \"\"\"\n",
    "    SELECT column_name, data_type, is_nullable\n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = 'products'\n",
    "    ORDER BY column_name;\n",
    "    \"\"\"\n",
    "    schema = con.execute(schema_query).df()\n",
    "   \n",
    "    # 2. Pour chaque colonne\n",
    "    results = []\n",
    "    for _, row in schema.iterrows():\n",
    "        col_name = row['column_name']\n",
    "        stats = {\n",
    "            'name': col_name,\n",
    "            'type': row['data_type'],\n",
    "            'nullable': row['is_nullable'],\n",
    "            'stats': {}\n",
    "        }\n",
    "       \n",
    "        # Statistiques de base\n",
    "        basic_stats = con.execute(f\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total,\n",
    "                COUNT(DISTINCT {col_name}) as unique_values,\n",
    "                COUNT(*) - COUNT({col_name}) as null_count\n",
    "            FROM products\n",
    "        \"\"\").fetchone()\n",
    "       \n",
    "        stats['stats'] = {\n",
    "            'total': basic_stats[0],\n",
    "            'unique_values': basic_stats[1],\n",
    "            'null_count': basic_stats[2]\n",
    "        }\n",
    "       \n",
    "        # Échantillon de valeurs\n",
    "        if col_name.endswith('_tags'):\n",
    "            # Pour les colonnes de type tableau\n",
    "            sample = con.execute(f\"\"\"\n",
    "                WITH expanded AS (\n",
    "                    SELECT DISTINCT elem\n",
    "                    FROM products, \n",
    "                            UNNEST({col_name}) AS elem\n",
    "                    WHERE {col_name} IS NOT NULL\n",
    "                    LIMIT 20\n",
    "                )\n",
    "                SELECT elem\n",
    "                FROM expanded\n",
    "                ORDER BY elem\n",
    "            \"\"\").fetchall()\n",
    "            stats['sample_values'] = [str(x[0]) for x in sample]\n",
    "        else:\n",
    "            # Pour les colonnes normales\n",
    "            sample = con.execute(f\"\"\"\n",
    "                SELECT DISTINCT {col_name}\n",
    "                FROM products\n",
    "                WHERE {col_name} IS NOT NULL\n",
    "                ORDER BY {col_name}\n",
    "                LIMIT 20\n",
    "            \"\"\").fetchall()\n",
    "            stats['sample_values'] = [str(x[0]) for x in sample]\n",
    "            \n",
    "        results.append(stats)\n",
    "   \n",
    "    # Générer le markdown\n",
    "    md = \"# Dictionnaire des données\\n\\n\"\n",
    "    for col in results:\n",
    "        md += f\"## {col['name']}\\n\"\n",
    "        md += f\"- Type: {col['type']}\\n\"\n",
    "        md += f\"- Nullable: {col['nullable']}\\n\"\n",
    "        md += f\"- Total rows: {col['stats']['total']}\\n\"\n",
    "        md += f\"- Unique values: {col['stats']['unique_values']}\\n\"\n",
    "        md += f\"- Null count: {col['stats']['null_count']}\\n\"\n",
    "        if 'sample_values' in col:\n",
    "            md += f\"- Sample values: {', '.join(col['sample_values'])}\\n\"\n",
    "        md += \"\\n\"\n",
    "   \n",
    "    # Sauvegarder\n",
    "    Path(\"../docs/markdown/data_dictionary.md\").write_text(md)\n",
    "   \n",
    "    con.close()\n",
    "\n",
    "analyze_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
